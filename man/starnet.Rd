% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/functions.R
\name{starnet}
\alias{starnet}
\title{Stacked Elastic Net Regression}
\usage{
starnet(y, X, family = "gaussian", nalpha = 21, alpha = NULL,
  nfolds = 10, foldid = NULL, type.measure = "deviance",
  alpha.meta = 1, grouped = TRUE, penalty.factor = NULL,
  intercept = NULL, upper.limit = NULL, unit.sum = NULL, ...)
}
\arguments{
\item{y}{numeric response\strong{:}
vector of length \eqn{n}}

\item{X}{covariates\strong{:}
numeric matrix with \eqn{n} rows (samples)
and \eqn{p} columns (variables)}

\item{family}{character "gaussian", "binomial" or "poisson"}

\item{nalpha}{number of \code{alpha} values}

\item{alpha}{elastic net mixing parameters\strong{:}
vector of values between \eqn{0} (ridge) and \eqn{1} (lasso);
or \code{NULL} (equidistance)}

\item{nfolds}{number of folds}

\item{foldid}{fold identifiers\strong{:}
vector with entries between \eqn{1} and \code{nfolds};
or \code{NULL} (balance)}

\item{type.measure}{loss function\strong{:}
character "deviance", "class", "mse" or "mae"
(see \code{\link[glmnet]{cv.glmnet}})}

\item{alpha.meta}{elastic net mixing parameters for stacking\strong{:}
vector of values between \eqn{0} (ridge) and \eqn{1} (lasso),
\emph{see details}}

\item{grouped}{logical}

\item{penalty.factor}{penalty factors for base-learners}

\item{intercept, upper.limit, unit.sum}{settings for meta-learner\strong{:} logical}

\item{...}{further arguments passed to \code{\link[glmnet]{glmnet}}}
}
\description{
Implements stacked elastic net regression.
}
\details{
Combine predictions from \emph{some} \code{alpha} with \code{alpha.meta}\eqn{=1},
or from \emph{all} \code{alpha} with \code{alpha.meta}\eqn{=0}.
We recommend to use \code{alpha.meta}\eqn{=0} (default) for stability.
}
\examples{
set.seed(1)
n <- 30; p <- 50
y <- rnorm(n=n)
X <- matrix(rnorm(n*p),nrow=n,ncol=p)
object <- starnet::starnet(y=y,X=X,family="gaussian")

}
\references{
A Rauschenberger, E Glaab, and MA van de Wiel (2020)
"Improved elastic net regression through stacked generalisation"
\emph{Manuscript in preparation.}
}
